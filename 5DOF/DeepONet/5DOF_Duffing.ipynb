{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d908e69-7d28-46fc-accb-f98fac79f5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## uncomment if new testing data is to be generated\n",
    "\n",
    "# %reset -f\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy.io as sp\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from keras.models import Model\n",
    "# from keras.layers.merge import concatenate\n",
    "# from tensorflow.keras import initializers, regularizers\n",
    "# from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "# from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "# dt = 0.01\n",
    "# min_t = 0\n",
    "# max_t = 2\n",
    "\n",
    "# t = np.arange(min_t, max_t, dt)\n",
    "# lt = t.shape[0]\n",
    "\n",
    "# samples = 1500\n",
    "\n",
    "# def rkm(y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, f, t):\n",
    "#     h = dt\n",
    "    \n",
    "#     F1 = lambda Y: Y[6]\n",
    "#     F2 = lambda Y: Y[7]\n",
    "#     F3 = lambda Y: Y[8]\n",
    "#     F4 = lambda Y: Y[9]\n",
    "#     F5 = lambda Y: Y[10]\n",
    "#     F6 = lambda Y: (1/M1)*(-M1*f-(C1*Y[5+1]+K1*Y[1]+C2*(Y[5+1]-Y[5+2])+K2*(Y[1]-Y[2])+alpha*Y[1]**3))\n",
    "#     F7 = lambda Y: (1/M2)*(-M2*f-(C2*(Y[5+2]-Y[5+1])+K2*(Y[2]-Y[1])+C3*(Y[5+2]-Y[5+3])+K3*(Y[2]-Y[3])))\n",
    "#     F8 = lambda Y: (1/M3)*(-M3*f-(C3*(Y[5+3]-Y[5+2])+K3*(Y[3]-Y[2])+C4*(Y[5+3]-Y[5+4])+K5*(Y[3]-Y[4])))\n",
    "#     F9 = lambda Y: (1/M4)*(-M4*f-(C4*(Y[5+4]-Y[5+3])+K4*(Y[4]-Y[3])+C5*(Y[5+4]-Y[5+5])+K5*(Y[4]-Y[5])))\n",
    "#     F10 = lambda Y: (1/M5)*(-M5*f-(C5*(Y[5+5]-Y[5+4])+K5*(Y[5]-Y[4])))\n",
    "\n",
    "\n",
    "#     k0 = h*F1([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     l0 = h*F2([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     m0 = h*F3([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     n0 = h*F4([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     o0 = h*F5([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     p0 = h*F6([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     q0 = h*F7([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     r0 = h*F8([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     s0 = h*F9([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#     t0 = h*F10([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "\n",
    "#     k1 = h*F1([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     l1 = h*F2([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     m1 = h*F3([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     n1 = h*F4([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     o1 = h*F5([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     p1 = h*F6([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     q1 = h*F7([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     r1 = h*F8([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     s1 = h*F9([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#     t1 = h*F10([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "    \n",
    "#     k2 = h*F1([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     l2 = h*F2([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     m2 = h*F3([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     n2 = h*F4([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     o2 = h*F5([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     p2 = h*F6([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     q2 = h*F7([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     r2 = h*F8([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     s2 = h*F9([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#     t2 = h*F10([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "    \n",
    "    \n",
    "#     k3 = h*F1([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     l3 = h*F2([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     m3 = h*F3([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     n3 = h*F4([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     o3 = h*F5([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     p3 = h*F6([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     q3 = h*F7([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     r3 = h*F8([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     s3 = h*F9([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#     t3 = h*F10([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "    \n",
    "#     y1 = y1+(1/6)*(k0+2*k1+2*k2+k3);\n",
    "#     y2 = y2+(1/6)*(l0+2*l1+2*l2+l3);\n",
    "#     y3 = y3+(1/6)*(m0+2*m1+2*m2+m3);\n",
    "#     y4 = y4+(1/6)*(n0+2*n1+2*n2+n3);\n",
    "#     y5 = y5+(1/6)*(o0+2*o1+2*o2+o3);\n",
    "#     y6 = y6+(1/6)*(p0+2*p1+2*p2+p3);\n",
    "#     y7 = y7+(1/6)*(q0+2*q1+2*q2+q3);\n",
    "#     y8 = y8+(1/6)*(r0+2*r1+2*r2+r3);\n",
    "#     y9 = y9+(1/6)*(s0+2*s1+2*s2+s3);\n",
    "#     y10 = y10+(1/6)*(t0+2*t1+2*t2+t3);\n",
    "    \n",
    "\n",
    "#     return y1, y2, y3, y4, y5, y6, y7, y8, y9, y10\n",
    "\n",
    "\n",
    "# y1 = np.zeros([lt, samples])+0.01\n",
    "# y2 = np.zeros([lt, samples])+0.01\n",
    "# y3 = np.zeros([lt, samples])+0.01\n",
    "# y4 = np.zeros([lt, samples])+0.01\n",
    "# y5 = np.zeros([lt, samples])+0.01\n",
    "# y6 = np.zeros([lt, samples])+0.05\n",
    "# y7 = np.zeros([lt, samples])+0.05\n",
    "# y8 = np.zeros([lt, samples])+0.05\n",
    "# y9 = np.zeros([lt, samples])+0.05\n",
    "# y10 = np.zeros([lt, samples])+0.05\n",
    "\n",
    "# ft = 20\n",
    "# am = np.random.uniform(-10, 10, [samples,ft])\n",
    "# fr = np.random.uniform(0, 10, [samples,ft])\n",
    "# s1 = np.arange(0,ft,2)\n",
    "# s2 = np.arange(1,ft,2)\n",
    "# f = np.zeros([lt, samples])\n",
    "# for i in range(0, samples):\n",
    "#     f[:, i] = (np.sum([am[i,j]*np.sin(fr[i,j]*t) for j in s1],0,keepdims=True) +\n",
    "#                np.sum([am[i,j]*np.cos(fr[i,j]*t) for j in s2],0,keepdims=True))\n",
    "\n",
    "# M1 = 10; M2 = 10; M3 = 9; M4 = 9; M5 = 7.5; alpha = 100;\n",
    "# C1 = 100; C2 = 100; C3 = 90; C4 = 90; C5 = 75; \n",
    "# K1 = 10000; K2 = 10000; K3 = 9000; K4 = 9000; K5 = 7500; \n",
    "\n",
    "# for i in range(0, samples):\n",
    "#     if i%100 ==  0 or i == samples-1: print('sample number  = ', i) \n",
    "#     for j in range(1, lt):\n",
    "#         y1[j, i], y2[j, i], y3[j, i], y4[j, i], y5[j, i], y6[j, i], y7[j, i], y8[j, i], y9[j, i], y10[j, i] = rkm(y1[j-1, i], y2[j-1, i], y3[j-1, i], y4[j-1, i], y5[j-1, i], y6[j-1, i], y7[j-1, i], y8[j-1, i], y9[j-1, i], y10[j-1, i], f[j-1, i], t[j-1])\n",
    "\n",
    "# # sp.savemat('data_5DOF_duffing.mat',{'f': f.T, 'y1': y1.T, 'y2': y2.T, 'y3': y3.T, 'y4': y4.T, 'y5': y5.T, 'am': am, 'fr': fr, 't': t, 'dt': dt})\n",
    "# sp.savemat('data_5DOF_duffing_1500_samples.mat',{'f': f.T, 'y1': y1.T, 'y2': y2.T, 'y3': y3.T, 'y4': y4.T, 'y5': y5.T, 'am': am, 'fr': fr, 't': t, 'dt': dt})\n",
    "\n",
    "# plt.plot(f[:,0])\n",
    "# plt.show()        \n",
    "# plt.plot(y1[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y2[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y3[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y4[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y5[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y6[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y7[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y8[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y9[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y10[:,0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4561bb-2473-4174-9172-7296650a17fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd00b7-7422-404e-9368-39e9de2a01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Code\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import time \n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# # Misc. function: if DeepXDE is to be run        \n",
    "# # Misc. function\n",
    "# def mean_squared_error_outlier(yt, yp):\n",
    "#     err = np.ravel((yt-yp)**2)\n",
    "#     err = np.sort(err)[: -len(err) // 1000]\n",
    "#     return np.mean(err)\n",
    "\n",
    "with tf.device('/device:cpu:0'):\n",
    "\n",
    "    dt = 0.01\n",
    "    min_t = 0\n",
    "    max_t = 2\n",
    "\n",
    "    t = np.arange(min_t, max_t, dt)\n",
    "    lt = t.shape[0]\n",
    "\n",
    "    training_samples = 500\n",
    "    mean_sq_error = 0\n",
    "\n",
    "    data = sp.loadmat('data_5DOF_duffing.mat')\n",
    "    f = data['f']\n",
    "\n",
    "    for disp_num in range (0,5):\n",
    "        if disp_num == 0:\n",
    "            y = data['y1']\n",
    "        elif disp_num == 1:\n",
    "            y = data['y2']\n",
    "        elif disp_num == 2:\n",
    "            y = data['y3']\n",
    "        elif disp_num == 3:\n",
    "            y = data['y4']\n",
    "        else:\n",
    "            y = data['y5']\n",
    "\n",
    "        train_n = training_samples\n",
    "\n",
    "        force = f\n",
    "\n",
    "        pointspsamples = 10 ## 25 for results shown in paper\n",
    "        pointer = np.random.randint(0,lt-1,train_n*pointspsamples)\n",
    "\n",
    "        UX = np.tile(f[0:train_n,0:-1:2],(pointspsamples,1))\n",
    "        Y = np.zeros([train_n*pointspsamples,1])\n",
    "        UXY = np.zeros([train_n*pointspsamples,1])\n",
    "\n",
    "        for i in range(0,pointspsamples):\n",
    "            for j in range(0,train_n):\n",
    "                Y[int(train_n*i+j),0] = t[pointer[train_n*i+j]]\n",
    "                UXY[int(train_n*i+j),0] = y[j,pointer[train_n*i+j]]\n",
    "\n",
    "        ux_sensors = 100\n",
    "        y_sensors = 1\n",
    "\n",
    "\n",
    "        # # # # # # # # # # # # # # # # # # # #    \n",
    "\n",
    "        def layer_dense(nodes = 1, activation_func = 'relu',\n",
    "                        kernel_init = initializers.GlorotNormal(),\n",
    "                        name = None):\n",
    "            layer = Dense(nodes, activation = activation_func,\n",
    "                         kernel_initializer = kernel_init,\n",
    "                         name = name)\n",
    "            return layer\n",
    "\n",
    "        def fn(x):\n",
    "            y = tf.einsum(\"ij,ij->i\", x[0], x[1])\n",
    "            y = tf.expand_dims(y, axis=1)\n",
    "            return y\n",
    "\n",
    "        hidden_layer_nodes = 40\n",
    "\n",
    "        layer_input_a = Input(shape = (ux_sensors, ), name = \"input_a\")    \n",
    "        normalizer_a = preprocessing.Normalization(input_shape = [ux_sensors, ], name = '15_a')\n",
    "        normalizer_a.adapt(UX)\n",
    "        layer_15_a = normalizer_a(layer_input_a)\n",
    "        layer_20_a = layer_dense(hidden_layer_nodes, name = '20_a')(layer_15_a)\n",
    "        layer_25_a = layer_dense(hidden_layer_nodes, name = '25_a')(layer_20_a)\n",
    "\n",
    "        layer_input_b = Input(shape = (y_sensors, ), name = \"input_b\")\n",
    "        normalizer_b = preprocessing.Normalization(input_shape = [y_sensors, ], name = '15_b')\n",
    "        normalizer_b.adapt(Y)\n",
    "        layer_15_b = normalizer_b(layer_input_b)    \n",
    "        layer_20_b = layer_dense(hidden_layer_nodes, name = '20_b')(layer_15_b)\n",
    "        layer_25_b = layer_dense(hidden_layer_nodes, name = '25_b')(layer_20_b)\n",
    "\n",
    "        layer_35 = Lambda(fn, output_shape = [None,1], name = '35')([layer_25_a, layer_25_b])\n",
    "        layer_40 = Dense(1, activation = None,\n",
    "                         kernel_initializer = initializers.GlorotNormal(),\n",
    "                         name = '40')(layer_35)\n",
    "\n",
    "        model = Model(inputs = [layer_input_a, layer_input_b], outputs = layer_40)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss = 'mse',\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      metrics = 'mae')\n",
    "\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_a\":UX, \"input_b\":Y}, UXY)).batch(128)\n",
    "\n",
    "        start_time = time.time()\n",
    "        for i in range(0,20):\n",
    "            print('iteration = '+str(i))\n",
    "            model.fit(train_dataset,\n",
    "                      epochs = 1, verbose = 1, batch_size = 128)\n",
    "            model.fit(train_dataset,\n",
    "                      epochs = 499, verbose = 0, batch_size = 128)\n",
    "        print('Time(s) --> ',time.time()-start_time)\n",
    "\n",
    "# # Misc. function: if DeepXDE is to be run        \n",
    "    #     from numpy.ma import MaskedArray\n",
    "    #     import sklearn.utils.fixes\n",
    "    #     sklearn.utils.fixes.MaskedArray = MaskedArray\n",
    "    #     import deepxde as dde\n",
    "\n",
    "    #     data_NN = dde.data.triple.Triple((UX, Y), UXY, (UX[-500:-1,:], Y[-500:-1,:]), UXY[-500:-1,:])\n",
    "    #     nn = dde.nn.tensorflow_compat_v1.DeepONet(\n",
    "    #         [100, 40, 40],\n",
    "    #         [1, 40, 40],\n",
    "    #         'relu',\n",
    "    #         'Glorot normal',\n",
    "    #         use_bias = True,\n",
    "    #         stacked = False)\n",
    "\n",
    "    #     model = dde.model.Model(data_NN, nn)\n",
    "    #     model.compile('adam', lr = 0.001, metrics = [mean_squared_error_outlier])\n",
    "    #     model.train(epochs = 10000)\n",
    "\n",
    "# # Saves trained models\n",
    "#         string = '10PPS_model_save_5DOF_nonlinear_'+str(train_n)+'_displacement_'+str(disp_num+1)\n",
    "#         model.save(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdede18e-e31d-42f5-a97a-1b11cd2f4245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b12cde-2d8e-47b5-bac8-c7882923ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5DOF_nonlinear_1500_displacement_1\n",
      "5DOF_nonlinear_1500_displacement_2\n",
      "5DOF_nonlinear_1500_displacement_3\n",
      "5DOF_nonlinear_1500_displacement_4\n",
      "5DOF_nonlinear_1500_displacement_5\n",
      "5DOF_nonlinear_1500_displacement_1\n",
      "5DOF_nonlinear_1500_displacement_2\n",
      "5DOF_nonlinear_1500_displacement_3\n",
      "5DOF_nonlinear_1500_displacement_4\n",
      "5DOF_nonlinear_1500_displacement_5\n",
      "5DOF_nonlinear_1500_displacement_1\n",
      "5DOF_nonlinear_1500_displacement_2\n",
      "5DOF_nonlinear_1500_displacement_3\n",
      "5DOF_nonlinear_1500_displacement_4\n",
      "5DOF_nonlinear_1500_displacement_5\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "with tf.device('/device:cpu:0'):\n",
    "    dt = 0.01\n",
    "    min_t = 0\n",
    "    max_t = 2\n",
    "\n",
    "    t = np.arange(min_t, max_t, dt)\n",
    "    lt = t.shape[0]\n",
    "\n",
    "    test_samples = 10000\n",
    "    \n",
    "    predicted = np.zeros([10000,200])\n",
    "    x_test_0_new = np.zeros([2000000, 100])\n",
    "    x_test_1_new = np.zeros([2000000, 1])\n",
    "\n",
    "# # uncomment if new training data is to be generated\n",
    "#     def rkm(y1, y2, y3, y4, y5, y6, y7, y8, y9, y10, f, t):\n",
    "#         h = dt\n",
    "\n",
    "#         F1 = lambda Y: Y[6]\n",
    "#         F2 = lambda Y: Y[7]\n",
    "#         F3 = lambda Y: Y[8]\n",
    "#         F4 = lambda Y: Y[9]\n",
    "#         F5 = lambda Y: Y[10]\n",
    "#         F6 = lambda Y: (1/M1)*(-M1*f-(C1*Y[5+1]+K1*Y[1]+C2*(Y[5+1]-Y[5+2])+K2*(Y[1]-Y[2])+alpha*Y[1]**3))\n",
    "#         F7 = lambda Y: (1/M2)*(-M2*f-(C2*(Y[5+2]-Y[5+1])+K2*(Y[2]-Y[1])+C3*(Y[5+2]-Y[5+3])+K3*(Y[2]-Y[3])))\n",
    "#         F8 = lambda Y: (1/M3)*(-M3*f-(C3*(Y[5+3]-Y[5+2])+K3*(Y[3]-Y[2])+C4*(Y[5+3]-Y[5+4])+K5*(Y[3]-Y[4])))\n",
    "#         F9 = lambda Y: (1/M4)*(-M4*f-(C4*(Y[5+4]-Y[5+3])+K4*(Y[4]-Y[3])+C5*(Y[5+4]-Y[5+5])+K5*(Y[4]-Y[5])))\n",
    "#         F10 = lambda Y: (1/M5)*(-M5*f-(C5*(Y[5+5]-Y[5+4])+K5*(Y[5]-Y[4])))\n",
    "\n",
    "\n",
    "#         k0 = h*F1([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         l0 = h*F2([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         m0 = h*F3([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         n0 = h*F4([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         o0 = h*F5([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         p0 = h*F6([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         q0 = h*F7([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         r0 = h*F8([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         s0 = h*F9([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "#         t0 = h*F10([t, y1, y2, y3, y4, y5, y6, y7, y8, y9, y10]);\n",
    "\n",
    "#         k1 = h*F1([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         l1 = h*F2([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         m1 = h*F3([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         n1 = h*F4([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         o1 = h*F5([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         p1 = h*F6([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         q1 = h*F7([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         r1 = h*F8([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         s1 = h*F9([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "#         t1 = h*F10([t+0.5*h, y1+0.5*k0, y2+0.5*l0, y3+0.5*m0, y4+0.5*n0, y5+0.5*o0, y6+0.5*p0, y7+0.5*q0, y8+0.5*r0, y9+0.5*s0, y10+0.5*t0]);\n",
    "\n",
    "#         k2 = h*F1([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         l2 = h*F2([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         m2 = h*F3([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         n2 = h*F4([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         o2 = h*F5([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         p2 = h*F6([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         q2 = h*F7([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         r2 = h*F8([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         s2 = h*F9([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "#         t2 = h*F10([t+0.5*h, y1+0.5*k1, y2+0.5*l1, y3+0.5*m1, y4+0.5*n1, y5+0.5*o1, y6+0.5*p1, y7+0.5*q1, y8+0.5*r1, y9+0.5*s1, y10+0.5*t1]);\n",
    "\n",
    "\n",
    "#         k3 = h*F1([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         l3 = h*F2([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         m3 = h*F3([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         n3 = h*F4([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         o3 = h*F5([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         p3 = h*F6([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         q3 = h*F7([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         r3 = h*F8([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         s3 = h*F9([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "#         t3 = h*F10([t+h, y1+k2, y2+l2, y3+m2, y4+n2, y5+o2, y6+p2, y7+q2, y8+r2, y9+s2, y10+t2]);\n",
    "\n",
    "#         y1 = y1+(1/6)*(k0+2*k1+2*k2+k3);\n",
    "#         y2 = y2+(1/6)*(l0+2*l1+2*l2+l3);\n",
    "#         y3 = y3+(1/6)*(m0+2*m1+2*m2+m3);\n",
    "#         y4 = y4+(1/6)*(n0+2*n1+2*n2+n3);\n",
    "#         y5 = y5+(1/6)*(o0+2*o1+2*o2+o3);\n",
    "#         y6 = y6+(1/6)*(p0+2*p1+2*p2+p3);\n",
    "#         y7 = y7+(1/6)*(q0+2*q1+2*q2+q3);\n",
    "#         y8 = y8+(1/6)*(r0+2*r1+2*r2+r3);\n",
    "#         y9 = y9+(1/6)*(s0+2*s1+2*s2+s3);\n",
    "#         y10 = y10+(1/6)*(t0+2*t1+2*t2+t3);\n",
    "\n",
    "\n",
    "#         return y1, y2, y3, y4, y5, y6, y7, y8, y9, y10\n",
    "\n",
    "    ft_terms = [20, 25, 50]\n",
    "\n",
    "    for num in range(0,3):\n",
    "\n",
    "        y1 = np.zeros([lt, test_samples])+0.01\n",
    "        y2 = np.zeros([lt, test_samples])+0.01\n",
    "        y3 = np.zeros([lt, test_samples])+0.01\n",
    "        y4 = np.zeros([lt, test_samples])+0.01\n",
    "        y5 = np.zeros([lt, test_samples])+0.01\n",
    "        y6 = np.zeros([lt, test_samples])+0.05\n",
    "        y7 = np.zeros([lt, test_samples])+0.05\n",
    "        y8 = np.zeros([lt, test_samples])+0.05\n",
    "        y9 = np.zeros([lt, test_samples])+0.05\n",
    "        y10 = np.zeros([lt, test_samples])+0.05\n",
    "\n",
    "        ft = ft_terms[num]\n",
    "        \n",
    "## uncomment if new training data is to be generated\n",
    "        # am = np.random.uniform(-10, 10, [test_samples,ft])\n",
    "        # fr = np.random.uniform(0, 10, [test_samples,ft])\n",
    "        # s1 = np.arange(0,ft,2)\n",
    "        # s2 = np.arange(1,ft,2)\n",
    "        # f = np.zeros([lt, test_samples])\n",
    "        # for i in range(0, test_samples):\n",
    "        #     f[:, i] = (np.sum([am[i,j]*np.sin(fr[i,j]*t) for j in s1],0,keepdims=True) +\n",
    "        #                np.sum([am[i,j]*np.cos(fr[i,j]*t) for j in s2],0,keepdims=True))\n",
    "\n",
    "#         M1 = 10; M2 = 10; M3 = 9; M4 = 9; M5 = 7.5; alpha = 100;\n",
    "#         C1 = 100; C2 = 100; C3 = 90; C4 = 90; C5 = 75; \n",
    "#         K1 = 10000; K2 = 10000; K3 = 9000; K4 = 9000; K5 = 7500; \n",
    "\n",
    "#         for i in range(0, test_samples):\n",
    "#             if i%1000 ==  0 or i == test_samples-1: print('sample number  = ', i) \n",
    "#             for j in range(1, lt):\n",
    "#                 y1[j, i], y2[j, i], y3[j, i], y4[j, i], y5[j, i], y6[j, i], y7[j, i], y8[j, i], y9[j, i], y10[j, i] = rkm(y1[j-1, i], y2[j-1, i], y3[j-1, i], y4[j-1, i], y5[j-1, i], y6[j-1, i], y7[j-1, i], y8[j-1, i], y9[j-1, i], y10[j-1, i], f[j-1, i], t[j-1])\n",
    "\n",
    "        string = '5DOF_DO_testing_data_FT_'+str(ft)+'.mat'\n",
    "#         sp.savemat(string,{'force': f, 'y1': y1, 'y2': y2, 'y3': y3, 'y4': y4, 'y5': y5, 'fourier_terms': ft})\n",
    "\n",
    "        test_data = sp.loadmat(string)\n",
    "        f = test_data['force']\n",
    "        y1 = test_data['y1']\n",
    "        y2 = test_data['y2']\n",
    "        y3 = test_data['y3']\n",
    "        y4 = test_data['y4']\n",
    "        y5 = test_data['y5']\n",
    "        \n",
    "        \n",
    "        x_test = f[0:-1:2,:].T\n",
    "\n",
    "        training_samples = [1500]\n",
    "        \n",
    "        for disp_num in range(0,5):\n",
    "            if disp_num == 0:\n",
    "                y = y1.T\n",
    "            elif disp_num == 1:\n",
    "                y = y2.T\n",
    "            elif disp_num == 2:\n",
    "                y = y3.T\n",
    "            elif disp_num == 3:\n",
    "                y = y4.T\n",
    "            else:\n",
    "                y = y5.T\n",
    "\n",
    "            for model_num in range(0,1):\n",
    "\n",
    "                ## **UNCOMMENT** with appropriate string name, Load saved models\n",
    "                string = 'model_save_5DOF_nonlinear_'+str(training_samples[model_num])+'_displacement_'+str(disp_num+1)\n",
    "                model = tf.keras.models.load_model(string)\n",
    "                print('5DOF_nonlinear_'+str(training_samples[model_num])+'_displacement_'+str(disp_num+1))\n",
    "                \n",
    "                for i in range(0,test_samples):\n",
    "                    x_test_0_new[lt*i:lt+lt*i,:] = np.tile(x_test[i,:],[200,1])\n",
    "                    x_test_1_new[lt*i:lt+lt*i,:] = t.reshape([lt,1])\n",
    "                \n",
    "                predictions_new = model({\"input_a\":x_test_0_new, \"input_b\":x_test_1_new})\n",
    "                predictions_new = np.array(predictions_new)\n",
    "                \n",
    "                for i in range(0,test_samples):\n",
    "                    predicted[i,:] = predictions_new[lt*i:lt+lt*i].reshape(1,-1)\n",
    "                    \n",
    "#                 string = '10PPS_5DOF_DO_training_samples_'+str(training_samples[model_num])+'_displacement_'+str(disp_num+1)+'_FT_'+str(ft)+'.mat' \n",
    "#                 sp.savemat(string,{'actual_y': y, 'predicted_y': predicted, 'model_num': training_samples[model_num],\n",
    "#                                                     'disp_num': disp_num+1, 'fourier_terms': ft})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b54ead8-481a-4de2-b079-329ab47ab666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
