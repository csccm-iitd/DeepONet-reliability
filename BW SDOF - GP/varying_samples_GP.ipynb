{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dbd06-0ce3-44e4-9a2d-677001402cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## New data generation, If required\n",
    "\n",
    "# %reset -f\n",
    "\n",
    "# import numpy as np\n",
    "# import scipy.io as spi\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# dt = 0.01\n",
    "# min_t = 0\n",
    "# max_t = 10\n",
    "\n",
    "# t = np.arange(min_t, max_t, dt)\n",
    "# lt = t.shape[0]\n",
    "\n",
    "# test_samples = 11000\n",
    "\n",
    "# def rkm(y1, y2, z, f, t):\n",
    "#     h = dt\n",
    "\n",
    "#     F1 = lambda Y: Y[2]\n",
    "#     F2 = lambda Y: (1/m)*(f-(c*Y[2]+k*Y[1]+(1-kr)*Qy*Y[3]))\n",
    "#     F3 = lambda Y: (1/Dy)*(alpha*Y[2]-gamma*Y[3]*np.abs(Y[2])*np.abs(Y[3])**(eta-1)-beta*Y[2]*(np.abs(Y[3]))**eta)    \n",
    "\n",
    "#     k0 = h*F1([t, y1, y2, z]);\n",
    "#     l0 = h*F2([t, y1, y2, z]);\n",
    "#     m0 = h*F3([t, y1, y2, z]);\n",
    "\n",
    "#     k1 = h*F1([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#     l1 = h*F2([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#     m1 = h*F3([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "\n",
    "#     k2 = h*F1([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#     l2 = h*F2([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#     m2 = h*F3([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "\n",
    "#     k3 = h*F1([t, y1+k2, y2+l2, z+m2]);\n",
    "#     l3 = h*F2([t, y1+k2, y2+l2, z+m2]);\n",
    "#     m3 = h*F3([t, y1+k2, y2+l2, z+m2]);\n",
    "\n",
    "#     y1 = y1+(1/6)*(k0+2*k1+2*k2+k3);\n",
    "#     y2 = y2+(1/6)*(l0+2*l1+2*l2+l3);\n",
    "#     z = z+(1/6)*(m0+2*m1+2*m2+m3);\n",
    "    \n",
    "#     return y1, y2, z\n",
    "\n",
    "# y1 = np.zeros([lt, test_samples])+0.005\n",
    "# y2 = np.zeros([lt, test_samples])+0.001\n",
    "# z = np.zeros([lt, test_samples])+0.001\n",
    "\n",
    "# l = 0.1\n",
    "# s = 50\n",
    "\n",
    "# mean = np.zeros([lt,])\n",
    "# cov = np.zeros([lt,lt])\n",
    "\n",
    "# f = np.zeros([lt, test_samples])\n",
    "# for i in range(0,lt):\n",
    "#     for j in range(i,lt):\n",
    "#         cov[i,j] = (s**2)*np.exp(-1*((t[i]-t[j])**2)/(2*l**2))\n",
    "#         cov[j,i] = cov[i,j]    \n",
    "\n",
    "# f = np.random.multivariate_normal(mean, cov, test_samples).T\n",
    "    \n",
    "# m = 6800; c = 3740; k = 232000\n",
    "# Qy = 0.05*m*9.81; kr = (1/6); alpha = 1\n",
    "# beta = 0.5; gamma = 0.5; Dy = 0.013; eta = 2 \n",
    "\n",
    "# for i in range(0, test_samples):\n",
    "#     if i%1000 ==  0 or i == test_samples-1: print('sample number  = ', i) \n",
    "#     for j in range(1, lt):\n",
    "#         y1[j, i], y2[j, i], z[j, i] = rkm(y1[j-1, i], y2[j-1, i], z[j-1, i], f[j-1, i], t[j-1])\n",
    "\n",
    "# plt.plot(f[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y1[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(y2[:,0])\n",
    "# plt.show()\n",
    "# plt.plot(z[:,0])\n",
    "# plt.show()\n",
    "\n",
    "# spi.savemat('GP_BW_data.mat',{'force': f, 'y1': y1, 'y2': y2, 'z': z, 't': t})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bcd31-c4d7-4880-a06b-d170fdae2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8fe56-4072-4f1a-82c3-9cbb4d1f7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model Training\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as spi\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "dt = 0.01\n",
    "min_t = 0\n",
    "max_t = 2\n",
    "\n",
    "t = np.arange(min_t, max_t, dt)\n",
    "lt = t.shape[0]\n",
    "\n",
    "test_n = 1000\n",
    "training_samples = [150, 250, 500, 750, 1000] ## 1000 in research paper results\n",
    "mean_sq_error = [0, 0, 0, 0, 0]\n",
    "\n",
    "data = spi.loadmat('GP_BW_data.mat')\n",
    "f = data['force'][0:lt,:].T\n",
    "y = data['y1'][0:lt,:].T\n",
    "\n",
    "for num in range(0,5):    \n",
    "    print('Training samples: '+str(training_samples[num]))\n",
    "    train_n = training_samples[num]\n",
    "    samples = 11000\n",
    "    \n",
    "    force = f\n",
    "\n",
    "    pointspsamples = 50\n",
    "    pointer = np.random.randint(0,lt-1,train_n*pointspsamples)\n",
    "    \n",
    "    UX = np.tile(f[0:train_n,0:-1:2],(pointspsamples,1))\n",
    "    Y = np.zeros([train_n*pointspsamples,1])\n",
    "    UXY = np.zeros([train_n*pointspsamples,1])\n",
    "\n",
    "    for i in range(0,pointspsamples):\n",
    "        for j in range(0,train_n):\n",
    "            Y[int(train_n*i+j),0] = t[pointer[train_n*i+j]]\n",
    "            UXY[int(train_n*i+j),0] = y[j,pointer[train_n*i+j]]\n",
    "    \n",
    "    ux_sensors = UX.shape[1]\n",
    "    y_sensors = Y.shape[1]\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # #    \n",
    "\n",
    "    with tf.device('/device:cpu:0'):\n",
    "        \n",
    "        def layer_dense(nodes = 1, activation_func = 'relu',\n",
    "                        kernel_init = initializers.GlorotNormal(),\n",
    "                        name = None):\n",
    "            layer = Dense(nodes, activation = activation_func,\n",
    "                         kernel_initializer = kernel_init,\n",
    "                         name = name)\n",
    "            return layer\n",
    "            \n",
    "        \n",
    "        def fn(x):\n",
    "            y = tf.einsum(\"ij,ij->i\", x[0], x[1])\n",
    "            y = tf.expand_dims(y, axis=1)\n",
    "            return y\n",
    "\n",
    "        hidden_layer_nodes = 40\n",
    "\n",
    "        layer_input_a = Input(shape = (ux_sensors, ), name = \"input_a\")    \n",
    "        normalizer_a = preprocessing.Normalization(input_shape = [ux_sensors, ], name = '15_a')\n",
    "        normalizer_a.adapt(UX)\n",
    "        layer_15_a = normalizer_a(layer_input_a)\n",
    "        layer_20_a = layer_dense(hidden_layer_nodes, name = '20_a')(layer_15_a)\n",
    "        layer_25_a = layer_dense(hidden_layer_nodes, name = '25_a')(layer_20_a)\n",
    "\n",
    "        layer_input_b = Input(shape = (y_sensors, ), name = \"input_b\")\n",
    "        normalizer_b = preprocessing.Normalization(input_shape = [y_sensors, ], name = '15_b')\n",
    "        normalizer_b.adapt(Y)\n",
    "        layer_15_b = normalizer_b(layer_input_b)    \n",
    "        layer_20_b = layer_dense(hidden_layer_nodes, name = '20_b')(layer_15_b)\n",
    "        layer_25_b = layer_dense(hidden_layer_nodes, name = '25_b')(layer_20_b)\n",
    "\n",
    "        layer_35 = Lambda(fn, output_shape = [None,1], name = '35')([layer_25_a, layer_25_b])\n",
    "        layer_40 = Dense(1, activation = None,\n",
    "                         kernel_initializer = initializers.GlorotNormal(),\n",
    "                         name = '40')(layer_35)\n",
    "\n",
    "        model = Model(inputs = [layer_input_a, layer_input_b], outputs = layer_40)\n",
    "        # model.summary()\n",
    "\n",
    "        model.compile(loss = 'mse',\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      metrics = 'mae')\n",
    "\n",
    "        start_time = time.time()\n",
    "        for i in range(0,5):\n",
    "            print('iteration = '+str(i))\n",
    "            model.fit({\"input_a\":UX, \"input_b\":Y}, UXY, epochs = 1, verbose = 1, batch_size = 128)\n",
    "            for i in range(0,999):\n",
    "                model.fit({\"input_a\":UX, \"input_b\":Y}, UXY, epochs = 1, verbose = 0, batch_size = 128)\n",
    "            \n",
    "        string = 'model_save_GP_BW_SDOF_'+str(train_n)\n",
    "        model.save(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da02d7d-e764-4bea-8b45-7174d51470aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20efa74-efea-4200-b3cc-51ba58de62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as spi\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "with tf.device('/device:cpu:0'):\n",
    "\n",
    "## uncomment if new testing data is to be generated     \n",
    "#     def rkm(y1, y2, z, f, t):\n",
    "#         h = dt\n",
    "\n",
    "#         F1 = lambda Y: Y[2]\n",
    "#         F2 = lambda Y: (1/m)*(f-(c*Y[2]+k*Y[1]+(1-kr)*Qy*Y[3]))\n",
    "#         F3 = lambda Y: (1/Dy)*(alpha*Y[2]-gamma*Y[3]*np.abs(Y[2])*np.abs(Y[3])**(eta-1)-beta*Y[2]*(np.abs(Y[3]))**eta)    \n",
    "\n",
    "#         k0 = h*F1([t, y1, y2, z]);\n",
    "#         l0 = h*F2([t, y1, y2, z]);\n",
    "#         m0 = h*F3([t, y1, y2, z]);\n",
    "\n",
    "#         k1 = h*F1([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#         l1 = h*F2([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#         m1 = h*F3([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "\n",
    "#         k2 = h*F1([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#         l2 = h*F2([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#         m2 = h*F3([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "\n",
    "#         k3 = h*F1([t, y1+k2, y2+l2, z+m2]);\n",
    "#         l3 = h*F2([t, y1+k2, y2+l2, z+m2]);\n",
    "#         m3 = h*F3([t, y1+k2, y2+l2, z+m2]);\n",
    "\n",
    "#         y1 = y1+(1/6)*(k0+2*k1+2*k2+k3);\n",
    "#         y2 = y2+(1/6)*(l0+2*l1+2*l2+l3);\n",
    "#         z = z+(1/6)*(m0+2*m1+2*m2+m3);\n",
    "\n",
    "#         return y1, y2, z\n",
    "    \n",
    "    predicted = np.zeros([10000,200])\n",
    "    x_test_0_new = np.zeros([2000000, 100])\n",
    "    x_test_1_new = np.zeros([2000000, 1])\n",
    "    \n",
    "#     for l_s_num in range(0,25):\n",
    "\n",
    "    l_terms = [0.05, 0.05, 0.05, 0.05, 0.05] ## here l = 0.05 ## in research paper, testing is done for l = 0.75, 0.5, 0.25, 0.1, 0.075, 0.05\n",
    "    # l_terms = [0.075, 0.075, 0.075, 0.075, 0.075] \n",
    "    # l_terms = [0.1, 0.1, 0.1, 0.1, 0.1] \n",
    "    # l_terms = [0.25, 0.25, 0.25, 0.25, 0.25] \n",
    "    # l_terms = [0.5, 0.5, 0.5, 0.5, 0.5] \n",
    "    # l_terms = [0.75, 0.75, 0.75, 0.75, 0.75] \n",
    "    \n",
    "    s_terms = [25, 50, 75, 100, 125]\n",
    "    mean_sq_error = np.zeros([5,5])\n",
    "    \n",
    "    for l_s_num in range(0,5): \n",
    "\n",
    "        dt = 0.01\n",
    "        min_t = 0\n",
    "        max_t = 2\n",
    "\n",
    "        t = np.arange(min_t, max_t, dt)\n",
    "        lt = t.shape[0]\n",
    "\n",
    "        test_samples = 10000\n",
    "\n",
    "## uncomment if new testing data is to be generated     \n",
    "#         y1 = np.zeros([lt, test_samples])+0.005\n",
    "#         y2 = np.zeros([lt, test_samples])+0.001\n",
    "#         z = np.zeros([lt, test_samples])+0.001\n",
    "\n",
    "        l = l_terms[l_s_num]\n",
    "        s = s_terms[l_s_num]\n",
    "\n",
    "#         mean = np.zeros([lt,])\n",
    "#         cov = np.zeros([lt,lt])\n",
    "\n",
    "#         f = np.zeros([lt, test_samples])\n",
    "#         for i in range(0,lt):\n",
    "#             for j in range(i,lt):\n",
    "#                 cov[i,j] = (s**2)*np.exp(-1*((t[i]-t[j])**2)/(2*l**2))\n",
    "#                 cov[j,i] = cov[i,j] \n",
    "                \n",
    "#         f = np.random.multivariate_normal(mean, cov, test_samples).T\n",
    "\n",
    "#         m = 6800; c = 3740; k = 232000\n",
    "#         Qy = 0.05*m*9.81; kr = (1/6); alpha = 1\n",
    "#         beta = 0.5; gamma = 0.5; Dy = 0.013; eta = 2 \n",
    "        \n",
    "#         start_time = time.time()\n",
    "#         print('\\nData:')\n",
    "        \n",
    "#         for i in range(0, test_samples):\n",
    "#             if i%1000 ==  0: print('sample number  = ', i) \n",
    "#             for j in range(1, lt):\n",
    "#                 y1[j, i], y2[j, i], z[j, i] = rkm(y1[j-1, i], y2[j-1, i], z[j-1, i], f[j-1, i], t[j-1])\n",
    "#         print(time.time()-start_time)\n",
    "\n",
    "#         string = 'GP_BW_SDOF_testing_data_L_'+str(l)+'_S_'+str(s)+'.mat'\n",
    "#         sp.savemat(string,{'force': f, 'y1': y1, 'y2': y2, 'z': z, 'l':l, 's':s})\n",
    "\n",
    "        string = 'GP_BW_SDOF_testing_data_L_'+str(l)+'_S_'+str(s)+'.mat'\n",
    "        Testing_data = spi.loadmat(string)\n",
    "        f = Testing_data['force']\n",
    "        y1 = Testing_data['y1']\n",
    "        \n",
    "        x_test = f[0:-1:2,:].T\n",
    "\n",
    "        # training_samples = [150, 250, 500, 750, 1000]\n",
    "        training_samples = [1000]\n",
    "        \n",
    "\n",
    "        y = y1.T\n",
    "        \n",
    "        for model_num in range(0,1): #5\n",
    "            string = 'model_save_GP_BW_SDOF_'+str(training_samples[model_num])\n",
    "            model = tf.keras.models.load_model(string)\n",
    "            print('GP_BW_SDOF_'+str(training_samples[model_num])+'_L_'+str(l)+'_S_'+str(s))\n",
    "\n",
    "            start_time = time.time()\n",
    "            for i in range(0,test_samples):\n",
    "                x_test_0_new[lt*i:lt+lt*i,:] = np.tile(x_test[i,:],[200,1])\n",
    "                x_test_1_new[lt*i:lt+lt*i,:] = t.reshape([lt,1])\n",
    "                \n",
    "            predictions_new = model({\"input_a\":x_test_0_new,\n",
    "                                     \"input_b\":x_test_1_new})\n",
    "\n",
    "            predictions_new = np.array(predictions_new)\n",
    "            for i in range(0,test_samples):\n",
    "                predicted[i,:] = predictions_new[lt*i:lt+lt*i].reshape(1,-1)\n",
    "            print(time.time()-start_time)\n",
    "\n",
    "#             string = 'GP_BW_SDOF_training_samples_'+str(training_samples[model_num])+'_L_'+str(l)+'_S_'+str(s)+'.mat' \n",
    "#             sp.savemat(string,{'actual_y': y, 'predicted_y': predicted, 'model_num': training_samples[model_num], 'l':l, 's':s})\n",
    "\n",
    "            error = (y-predicted)\n",
    "            mean_sq_error[l_s_num, model_num] = np.mean(error**2)\n",
    "\n",
    "#         plt.figure(figsize = [30,15])\n",
    "\n",
    "#         string = 'MSE(y)'\n",
    "#         plt.plot(training_samples,mean_sq_error[0,:], 'o--', label = string)\n",
    "\n",
    "#         plt.xlabel('Training Samples',fontsize = 20)\n",
    "#         plt.ylabel('MSE',fontsize = 20)\n",
    "#         plt.tick_params(axis = 'x', labelsize = 20)\n",
    "#         plt.tick_params(axis = 'y', labelsize = 20)\n",
    "#         plt.legend(fontsize = 20)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f43f0-221e-4efd-b07c-27ffda7518ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
