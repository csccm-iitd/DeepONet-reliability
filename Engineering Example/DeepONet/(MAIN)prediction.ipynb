{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bedc30f-c164-4ec0-9985-ef10a3ef8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training models\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as spi\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "dof = 76\n",
    "data = spi.loadmat('data_400_samples_fs_100Hz_76_storey_NL_20FT.mat')\n",
    "ytotal = data['y'][0:dof,:,:].T\n",
    "f = data['f'][:,:].T\n",
    "\n",
    "for disp_num in [5-1, 15-1, 35-1, 65-1, 75-1]: ## [10-1, 15-1, 35-1, 65-1, 75-1] for research paper equivalence\n",
    "    print(disp_num)\n",
    "    dt = 0.01\n",
    "    min_t = 0\n",
    "    max_t = 2\n",
    "\n",
    "    t = np.arange(min_t, max_t, dt)\n",
    "    lt = t.shape[0]\n",
    "\n",
    "    y = ytotal[:,:,disp_num]\n",
    "\n",
    "    print('Displacement number: '+str(disp_num+1)+', Training samples: 400, PPS: 100')\n",
    "    train_n = 400\n",
    "\n",
    "    pointspsamples = 100\n",
    "    pointer = np.random.randint(0,lt-1,train_n*pointspsamples)\n",
    "    \n",
    "    UX = np.tile(f[0:train_n,0:-1:2],(pointspsamples,1))\n",
    "    Y = np.zeros([train_n*pointspsamples,1])\n",
    "    UXY = np.zeros([train_n*pointspsamples,1])\n",
    "\n",
    "    for i in range(0,pointspsamples):\n",
    "        for j in range(0,train_n):\n",
    "            Y[int(train_n*i+j),0] = t[pointer[train_n*i+j]]\n",
    "            UXY[int(train_n*i+j),0] = y[j,pointer[train_n*i+j]]\n",
    "    \n",
    "    ux_sensors = UX.shape[1]\n",
    "    y_sensors = Y.shape[1]\n",
    "    \n",
    "        # # # # # # # # # # # # # # # # # # # #    \n",
    "    \n",
    "    with tf.device('/device:cpu:0'):       \n",
    "        \n",
    "        def layer_dense(nodes = 1, activation_func = 'relu',\n",
    "                        kernel_init = initializers.GlorotNormal(),\n",
    "                        name = None):\n",
    "            layer = Dense(nodes, activation = activation_func,\n",
    "                         kernel_initializer = kernel_init,\n",
    "                         name = name)\n",
    "            return layer\n",
    "\n",
    "        def fn(x):\n",
    "            y = tf.einsum(\"ij,ij->i\", x[0], x[1])\n",
    "            y = tf.expand_dims(y, axis=1)\n",
    "            return y\n",
    "\n",
    "        hidden_layer_nodes = 40\n",
    "\n",
    "        layer_input_a = Input(shape = (ux_sensors, ), name = \"input_a\")    \n",
    "        normalizer_a = preprocessing.Normalization(input_shape = [ux_sensors, ], name = '15_a')\n",
    "        normalizer_a.adapt(UX)\n",
    "        layer_15_a = normalizer_a(layer_input_a)\n",
    "        layer_20_a = layer_dense(hidden_layer_nodes, name = '20_a')(layer_15_a)\n",
    "        layer_25_a = layer_dense(hidden_layer_nodes, name = '25_a')(layer_20_a)\n",
    "\n",
    "        layer_input_b = Input(shape = (y_sensors, ), name = \"input_b\")\n",
    "        normalizer_b = preprocessing.Normalization(input_shape = [y_sensors, ], name = '15_b')\n",
    "        normalizer_b.adapt(Y)\n",
    "        layer_15_b = normalizer_b(layer_input_b)    \n",
    "        \n",
    "        layer_20_b = layer_dense(hidden_layer_nodes, name = '20_b')(layer_15_b)\n",
    "        layer_25_b = layer_dense(hidden_layer_nodes, name = '25_b')(layer_20_b)\n",
    "\n",
    "        layer_35 = Lambda(fn, output_shape = [None,1], name = '35')([layer_25_a, layer_25_b])\n",
    "        layer_40 = Dense(1, activation = None,\n",
    "                         kernel_initializer = initializers.GlorotNormal(),\n",
    "                         name = '40')(layer_35)\n",
    "\n",
    "        model = Model(inputs = [layer_input_a, layer_input_b], outputs = layer_40)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss = 'mse',\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      metrics = 'mae')\n",
    "\n",
    "        for i in range(0,5):\n",
    "            print('iteration = '+str(i))\n",
    "            model.fit({\"input_a\":UX, \"input_b\":Y}, UXY,\n",
    "                      epochs = 1, verbose = 1, batch_size = 128)\n",
    "            for j in range(0,999):\n",
    "                model.fit({\"input_a\":UX, \"input_b\":Y}, UXY, epochs = 1, verbose = 0, batch_size = 128)\n",
    "\n",
    "        string = 'model_save_76DOF_NONLINEAR_'+str(train_n)+'_DISP_'+str(disp_num+1)\n",
    "        model.save(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961b544-a7e8-4d0c-9da7-25d428fca669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
