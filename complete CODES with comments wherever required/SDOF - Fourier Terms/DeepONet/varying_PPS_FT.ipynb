{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bcd31-c4d7-4880-a06b-d170fdae2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8fe56-4072-4f1a-82c3-9cbb4d1f7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "dt = 0.01\n",
    "min_t = 0\n",
    "max_t = 2\n",
    "\n",
    "t = np.arange(min_t, max_t, dt)\n",
    "lt = t.shape[0]\n",
    "\n",
    "test_n = 1000\n",
    "pointspsamples_array = [1, 25, 50, 75, 100] ## number of points per sample.\n",
    "mean_sq_error = [0, 0, 0, 0, 0]\n",
    "\n",
    "data = sp.loadmat('BW_data.mat')\n",
    "f = data['force'][0:lt,:].T\n",
    "y = data['y1'][0:lt,:].T\n",
    "\n",
    "for num in range(0,5): ## 5 because number of pointspsamples_array has 5 cases. \n",
    "    print('Points Per Sample: '+str(pointspsamples_array[num]))\n",
    "    train_n = 150 ## number of Training Samples, in research paper, traing is done for 25, 50, 75, 100 and 150 samples\n",
    "    samples = 11000 \n",
    "\n",
    "    pointer = np.random.randint(0,lt-1,samples) \n",
    "\n",
    "    force = f\n",
    "    time = t[pointer]\n",
    "    displacement = [y[i,pointer[i]] for i in range(0,samples)]\n",
    "\n",
    "    pointspsamples = pointspsamples_array[num]\n",
    "    pointer = np.random.randint(0,lt-1,train_n*pointspsamples)\n",
    "    \n",
    "    UX = np.tile(f[0:train_n,0:-1:2],(pointspsamples,1))\n",
    "    Y = np.zeros([train_n*pointspsamples,1])\n",
    "    UXY = np.zeros([train_n*pointspsamples,1])\n",
    "\n",
    "    for i in range(0,pointspsamples):\n",
    "        for j in range(0,train_n):\n",
    "            Y[int(train_n*i+j),0] = t[pointer[train_n*i+j]]\n",
    "            UXY[int(train_n*i+j),0] = y[j,pointer[train_n*i+j]]\n",
    "    \n",
    "    ux_sensors = UX.shape[1]\n",
    "    y_sensors = Y.shape[1]\n",
    "\n",
    "    # # # # # # # # # # # # # # # # # # # #    \n",
    "\n",
    "    with tf.device('/device:cpu:0'):\n",
    "        \n",
    "        def layer_dense(nodes = 1, activation_func = 'relu',\n",
    "                        kernel_init = initializers.GlorotNormal(),\n",
    "                        name = None):\n",
    "            layer = Dense(nodes, activation = activation_func,\n",
    "                         kernel_initializer = kernel_init,\n",
    "                         name = name)\n",
    "            return layer\n",
    "            \n",
    "        \n",
    "        def fn(x):\n",
    "            y = tf.einsum(\"ij,ij->i\", x[0], x[1])\n",
    "            y = tf.expand_dims(y, axis=1)\n",
    "            return y\n",
    "\n",
    "        hidden_layer_nodes = 40\n",
    "\n",
    "        layer_input_a = Input(shape = (ux_sensors, ), name = \"input_a\")    \n",
    "        normalizer_a = preprocessing.Normalization(input_shape = [ux_sensors, ], name = '15_a')\n",
    "        normalizer_a.adapt(UX)\n",
    "        layer_15_a = normalizer_a(layer_input_a)\n",
    "        layer_20_a = layer_dense(hidden_layer_nodes, name = '20_a')(layer_15_a)\n",
    "        layer_25_a = layer_dense(hidden_layer_nodes, name = '25_a')(layer_20_a)\n",
    "\n",
    "        layer_input_b = Input(shape = (y_sensors, ), name = \"input_b\")\n",
    "        normalizer_b = preprocessing.Normalization(input_shape = [y_sensors, ], name = '15_b')\n",
    "        normalizer_b.adapt(Y)\n",
    "        layer_15_b = normalizer_b(layer_input_b)    \n",
    "        layer_20_b = layer_dense(hidden_layer_nodes, name = '20_b')(layer_15_b)\n",
    "        layer_25_b = layer_dense(hidden_layer_nodes, name = '25_b')(layer_20_b)\n",
    "\n",
    "        layer_35 = Lambda(fn, output_shape = [None,1], name = '35')([layer_25_a, layer_25_b])\n",
    "        layer_40 = Dense(1, activation = None,\n",
    "                         kernel_initializer = initializers.GlorotNormal(),\n",
    "                         name = '40')(layer_35)\n",
    "\n",
    "        model = Model(inputs = [layer_input_a, layer_input_b], outputs = layer_40)\n",
    "        # model.summary()\n",
    "\n",
    "        model.compile(loss = 'mse',\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      metrics = 'mae')\n",
    "\n",
    "        for i in range(0,5):\n",
    "            print('iteration = '+str(i))\n",
    "            model.fit({\"input_a\":UX, \"input_b\":Y}, UXY,\n",
    "                      epochs = 1, verbose = 1, batch_size = 128)\n",
    "            for j in range(0,999):\n",
    "                model.fit({\"input_a\":UX, \"input_b\":Y}, UXY,\n",
    "                          epochs = 1, verbose = 0, batch_size = 128)\n",
    "\n",
    "        string = 'model_save_BW_SDOF_TRAIN_150_TIME_STEP_SPER_SAMPLE_'+str(pointspsamples)\n",
    "        model.save(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da02d7d-e764-4bea-8b45-7174d51470aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20efa74-efea-4200-b3cc-51ba58de62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.io as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.layers import Dense, Input, Lambda, Dot\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "with tf.device('/device:cpu:0'):\n",
    "    \n",
    "    predicted = np.zeros([10000,200])\n",
    "    x_test_0_new = np.zeros([2000000, 100])\n",
    "    x_test_1_new = np.zeros([2000000, 1])\n",
    "\n",
    "# #  Uncomment if new testing dataset is to be generated\n",
    "\n",
    "#     def rkm(y1, y2, z, f, t):\n",
    "#         h = dt\n",
    "\n",
    "#         F1 = lambda Y: Y[2]\n",
    "#         F2 = lambda Y: (1/m)*(f-(c*Y[2]+k*Y[1]+(1-kr)*Qy*Y[3]))\n",
    "#         F3 = lambda Y: (1/Dy)*(alpha*Y[2]-gamma*Y[3]*np.abs(Y[2])*np.abs(Y[3])**(eta-1)-beta*Y[2]*(np.abs(Y[3]))**eta)    \n",
    "\n",
    "#         k0 = h*F1([t, y1, y2, z]);\n",
    "#         l0 = h*F2([t, y1, y2, z]);\n",
    "#         m0 = h*F3([t, y1, y2, z]);\n",
    "\n",
    "#         k1 = h*F1([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#         l1 = h*F2([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "#         m1 = h*F3([t+0.5*h, y1+0.5*k0, y2+0.5*l0, z+0.5*m0]);\n",
    "\n",
    "#         k2 = h*F1([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#         l2 = h*F2([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "#         m2 = h*F3([t+0.5*h, y1+0.5*k1, y2+0.5*l1, z+0.5*m1]);\n",
    "\n",
    "#         k3 = h*F1([t, y1+k2, y2+l2, z+m2]);\n",
    "#         l3 = h*F2([t, y1+k2, y2+l2, z+m2]);\n",
    "#         m3 = h*F3([t, y1+k2, y2+l2, z+m2]);\n",
    "\n",
    "#         y1 = y1+(1/6)*(k0+2*k1+2*k2+k3);\n",
    "#         y2 = y2+(1/6)*(l0+2*l1+2*l2+l3);\n",
    "#         z = z+(1/6)*(m0+2*m1+2*m2+m3);\n",
    "\n",
    "#         return y1, y2, z\n",
    "\n",
    "    for ft_num in range(0,5): ## 5 because, 5 cases of fourier terms is considered \n",
    "\n",
    "        ft_terms = [20, 25, 50, 75, 100]\n",
    "\n",
    "        dt = 0.01\n",
    "        min_t = 0\n",
    "        max_t = 2\n",
    "\n",
    "        t = np.arange(min_t, max_t, dt)\n",
    "        lt = t.shape[0]\n",
    "\n",
    "        test_samples = 10000\n",
    "\n",
    "# #  Uncomment if new testing dataset is to be generated\n",
    "#         y1 = np.zeros([lt, test_samples])+0.01\n",
    "#         y2 = np.zeros([lt, test_samples])+0.05\n",
    "#         z = np.zeros([lt, test_samples])+0.001\n",
    "\n",
    "        ft = ft_terms[ft_num]\n",
    "\n",
    "# #  Uncomment if new testing dataset is to be generated\n",
    "#         am = np.random.uniform(-50, 50, [test_samples,ft])\n",
    "#         fr = np.random.uniform(0, 10, [test_samples,ft])\n",
    "#         s1 = np.arange(0,ft,2)\n",
    "#         s2 = np.arange(1,ft,2)\n",
    "#         f = np.zeros([lt, test_samples])\n",
    "#         for i in range(0, test_samples):\n",
    "#             f[:, i] = (np.sum([am[i,j]*np.sin(fr[i,j]*t) for j in s1],0,keepdims=True) +\n",
    "#                        np.sum([am[i,j]*np.cos(fr[i,j]*t) for j in s2],0,keepdims=True))\n",
    "\n",
    "#         m = 6800; c = 3740; k = 232000\n",
    "#         Qy = 0.05*m*9.81; kr = (1/6); alpha = 1\n",
    "#         beta = 0.5; gamma = 0.5; Dy = 0.013; eta = 2 \n",
    "\n",
    "#         for i in range(0, test_samples):\n",
    "#             if i%1000 ==  0 or i == test_samples-1: print('sample number  = ', i) \n",
    "#             for j in range(1, lt):\n",
    "#                 y1[j, i], y2[j, i], z[j, i] = rkm(y1[j-1, i], y2[j-1, i], z[j-1, i], f[j-1, i], t[j-1])\n",
    "\n",
    "#         string = 'BW_SDOF_testing_data_varying_PPS_FT_'+str(ft)+'.mat'\n",
    "#         sp.savemat(string,{'force': f, 'y1': y1, 'y2': y2, 'z': z, 'fourier_terms': ft})\n",
    "\n",
    "        string = 'BW_SDOF_testing_data_FT_'+str(ft)+'.mat'\n",
    "        Testing_data = sp.loadmat(string)\n",
    "        \n",
    "        f = Testing_data['force']\n",
    "        y1 = Testing_data['y1']\n",
    "\n",
    "        x_test = f[0:-1:2,:].T\n",
    "\n",
    "        pointspsamples_array = [1, 25, 50, 75, 100]\n",
    "        mean_sq_error = np.zeros([1,5])\n",
    "\n",
    "        y = y1.T\n",
    "\n",
    "        for model_num in range(0,5):\n",
    "            \n",
    "            string = 'model_save_BW_SDOF_TRAIN_150_TIME_STEP_SPER_SAMPLE_'+str(pointspsamples_array[model_num])\n",
    "            model = tf.keras.models.load_model(string)\n",
    "            print('\\nBW_SDOF_PPS'+str(pointspsamples_array[model_num]))\n",
    "\n",
    "            start_time = time.time()\n",
    "            for i in range(0,test_samples):\n",
    "                x_test_0_new[lt*i:lt+lt*i,:] = np.tile(x_test[i,:],[200,1])\n",
    "                x_test_1_new[lt*i:lt+lt*i,:] = t.reshape([lt,1])\n",
    "\n",
    "            predictions_new = model({\"input_a\":x_test_0_new,\n",
    "                                     \"input_b\":x_test_1_new})\n",
    "\n",
    "            predictions_new = np.array(predictions_new)\n",
    "            for i in range(0,test_samples):\n",
    "                predicted[i,:] = predictions_new[lt*i:lt+lt*i].reshape(1,-1)\n",
    "            print(time.time()-start_time)\n",
    "\n",
    "#             string = 'BW_SDOF_training_samples_150_PPS'+str(pointspsamples_array[model_num])+'_FT_'+str(ft)+'.mat' \n",
    "#             sp.savemat(string,{'actual_y': y, 'predicted_y': predicted, 'PPS': pointspsamples_array[model_num], 'fourier_terms': ft})\n",
    "\n",
    "\n",
    "            error = (y-predicted)\n",
    "            mean_sq_error[0, model_num] = np.mean(error**2)\n",
    "\n",
    "        plt.figure(figsize = [30,15])\n",
    "\n",
    "        string = 'MSE(y)'\n",
    "        plt.plot(pointspsamples_array,mean_sq_error[0,:], 'o--', label = string)\n",
    "\n",
    "        plt.xlabel('PPS',fontsize = 20)\n",
    "        plt.ylabel('MSE',fontsize = 20)\n",
    "        plt.tick_params(axis = 'x', labelsize = 20)\n",
    "        plt.tick_params(axis = 'y', labelsize = 20)\n",
    "        plt.legend(fontsize = 20)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eceb105-5220-49cd-8fce-b9d179aefd72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
